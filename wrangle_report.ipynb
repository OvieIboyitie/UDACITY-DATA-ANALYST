{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ee443b",
   "metadata": {},
   "source": [
    "**OVIE IBOYITIE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cab4b",
   "metadata": {},
   "source": [
    "# Data Wranglin Report\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#gather\">Gathering Data</a></li>\n",
    "<li><a href=\"#access\">Assessing data</a></li>\n",
    "<li><a href=\"#clean\">Cleaning data</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb1886",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "## Gathering Data \n",
    "In this project three data, werre used and are described below:\n",
    "- The WeRateDogs Twitter archive. \n",
    "This file was manually downloaded from the udacity website the following link: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv\n",
    "Once it is was downloaded, it was read into a pandas DataFrame.\n",
    "- The tweet image predictions, i.e., what breed of dog (or other object, animal,etc.) is present in each tweet according to a neural network. \n",
    "This file (image_predictions.tsv) hosted on Udacity’s servers and it was downloaded it programmatically\n",
    "using python Requests library on the following (URL of the file:\n",
    "https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_imagepredictions/image-predictions.tsv)\n",
    "- Each tweet’s retweet count and favorite (i.e. “like”) count and any additional data we found interesting. \n",
    " Using the tweet IDs in the WeRateDogs Twitter archive, the Twitter API was queried for each tweet's JSON data using Python's Tweepy library and stored each tweet's entire set of JSON data in a file called tweet-json.txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4540cc",
   "metadata": {},
   "source": [
    "<a id='access'></a>\n",
    "## Accessing the data\n",
    "After gathering each of the data, they were assessed visually and programmatically for quality and tidiness issues. \n",
    "- Quality (content issues): Checks for the Completeness, Validity, Accuracy, Consistency \n",
    "- Tidiness (structural issues)\n",
    " \n",
    "  - The following quality and tidiness issues were detected and documented \n",
    "  \n",
    "### Twitter API (twitter data)\n",
    "**QUALITY ISSUES**\n",
    "\n",
    "- Wrong datatype (tweet_id)\n",
    "- Missing tweets\n",
    "\n",
    "**TIDINESS ISSUE**\n",
    "- twitter api table columns(retweet_count, favorite_count, followers_count) should be added to twitter archive table.\n",
    "\n",
    "### Image prediction\n",
    "**QUALITY ISSUES**\n",
    "\n",
    "- Wrong datatype (tweet_id)\n",
    "- Missing images. The data contains only 2075 images out of possible 2356 images\n",
    "\n",
    "**TIDINESS ISSUES**\n",
    "- Image predictions table should be added to twitter archuve table\n",
    "\n",
    "### Twitter archive table\n",
    "**QUALITY**\n",
    "\n",
    "- Keep original ratings (no retweets) that have images\n",
    "- drop columns not needed for our analysis\n",
    "- Erroneous datatypes in these columns (tweet_id, rating_denominator,rating_numerator, in_reply_to_status_id, in_reply_to_user_id, timestamp, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, doggo, floofer, pupper, and puppo)\n",
    "- Correct numerators with decimals\n",
    "- Missing values in 'name' and dog stages represented as 'None'\n",
    "- Some records have more than on dog stage\n",
    "- Missing URLs in expanded_urls\n",
    "- Source column is in HTML-formatted string, not a normal string\n",
    "- Error in dog names (e.g a,an,actually) are not a dog's name.\n",
    "- Some values in rating_numerator and rating_denominator seem to be in error or suspicious outliers.\n",
    "- text column includes a text and a short link.\n",
    "\n",
    "**TIDINESS**\n",
    "\n",
    "- doggo, floofer, pupper and puppo columns in twitter_archive table should be merged into one column named \"dog_stage\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a57320",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "## Cleaning\n",
    "\n",
    "After gathering and accessing the data, Cleaning the data is the third step in data wrangling. It is stage where we fixed the quality and tidiness issues that we identified in the assess step.\n",
    "We used the programmatic approach to cleaning the data, but manual approach was used for the issues that were one-off occurrences. Our process was Define, Code and Test and we were always making a copy of tha dataset even we made the copy in file to test the change before applying to the main dataset. We didn’t spot all the quality and tidiness assessments at the\n",
    "assessing data section, so we have been iterating and revisiting assessing to add these assessments to our notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010327c",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusion\n",
    "\n",
    "Data wrangling indeed is a core skill that everyone who works with data should be familiar with\n",
    "since so much of the world’s data isn’t clean. If we analyze, visualize, or model our data before we\n",
    "wrangle it, our consequences could be making mistakes, missing out on cool insights, and wasting\n",
    "time. We couldn’t be able to make some of the visualization without wrangling (i.e dog gender\n",
    "partition) So best practices say wrangle. Always"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
